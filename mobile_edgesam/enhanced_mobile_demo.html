<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>EdgeSAM Mobile - Enhanced</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: #f5f5f5;
            padding: 10px;
        }
        
        .container {
            max-width: 100%;
            margin: 0 auto;
            background: white;
            border-radius: 12px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            overflow: hidden;
        }
        
        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            text-align: center;
        }
        
        .header h1 {
            font-size: 24px;
            margin-bottom: 8px;
        }
        
        .header p {
            opacity: 0.9;
            font-size: 14px;
        }
        
        .controls {
            padding: 20px;
            border-bottom: 1px solid #eee;
        }
        
        .file-input-wrapper {
            position: relative;
            display: inline-block;
            width: 100%;
            margin-bottom: 15px;
        }
        
        .file-input {
            display: none;
        }
        
        .file-input-label {
            display: block;
            padding: 12px 20px;
            background: #4CAF50;
            color: white;
            border-radius: 8px;
            text-align: center;
            cursor: pointer;
            font-weight: 500;
            transition: background 0.3s;
        }
        
        .file-input-label:hover {
            background: #45a049;
        }
        
        .point-type {
            display: flex;
            gap: 10px;
            margin-bottom: 15px;
        }
        
        .point-type label {
            flex: 1;
            padding: 10px;
            border: 2px solid #ddd;
            border-radius: 8px;
            text-align: center;
            cursor: pointer;
            transition: all 0.3s;
        }
        
        .point-type input[type="radio"] {
            display: none;
        }
        
        .point-type input[type="radio"]:checked + label {
            background: #4CAF50;
            color: white;
            border-color: #4CAF50;
        }
        
        .buttons {
            display: flex;
            gap: 10px;
        }
        
        .btn {
            flex: 1;
            padding: 12px;
            border: none;
            border-radius: 8px;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.3s;
        }
        
        .btn-primary {
            background: #2196F3;
            color: white;
        }
        
        .btn-primary:hover {
            background: #1976D2;
        }
        
        .btn-secondary {
            background: #f44336;
            color: white;
        }
        
        .btn-secondary:hover {
            background: #d32f2f;
        }
        
        .btn-clear {
            background: #ff9800;
            color: white;
        }
        
        .btn-clear:hover {
            background: #f57c00;
        }
        
        .image-container {
            position: relative;
            width: 100%;
            max-width: 100%;
            margin: 0 auto;
            background: #f9f9f9;
            border-radius: 8px;
            overflow: hidden;
        }
        
        #canvas {
            display: block;
            width: 100%;
            height: auto;
            cursor: crosshair;
        }
        
        .status {
            padding: 15px 20px;
            background: #e3f2fd;
            border-left: 4px solid #2196F3;
            margin: 10px 0;
            border-radius: 0 8px 8px 0;
        }
        
        .loading {
            display: none;
            text-align: center;
            padding: 20px;
        }
        
        .spinner {
            border: 3px solid #f3f3f3;
            border-top: 3px solid #3498db;
            border-radius: 50%;
            width: 30px;
            height: 30px;
            animation: spin 1s linear infinite;
            margin: 0 auto 10px;
        }
        
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        
        .instructions {
            padding: 20px;
            background: #f8f9fa;
            border-radius: 8px;
            margin: 10px 0;
        }
        
        .instructions h3 {
            color: #333;
            margin-bottom: 10px;
        }
        
        .instructions ol {
            color: #666;
            line-height: 1.6;
        }
        
        .instructions li {
            margin-bottom: 5px;
        }
        
        .point {
            position: absolute;
            width: 12px;
            height: 12px;
            border-radius: 50%;
            border: 2px solid white;
            transform: translate(-50%, -50%);
            pointer-events: none;
            z-index: 10;
        }
        
        .point.positive {
            background: #4CAF50;
        }
        
        .point.negative {
            background: #f44336;
        }
        
        .mask-overlay {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            pointer-events: none;
            z-index: 5;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üì± EdgeSAM Mobile Enhanced</h1>
            <p>Using proven web demo approach - runs on your phone's CPU</p>
        </div>
        
        <div class="controls">
            <div class="file-input-wrapper">
                <input type="file" id="imageInput" class="file-input" accept="image/*">
                <label for="imageInput" class="file-input-label">
                    üì∏ Choose Image or Take Photo
                </label>
            </div>
            
            <div class="point-type">
                <input type="radio" id="positive" name="pointType" value="positive" checked>
                <label for="positive">‚úÖ Positive Point</label>
                
                <input type="radio" id="negative" name="pointType" value="negative">
                <label for="negative">‚ùå Negative Point</label>
            </div>
            
            <div class="buttons">
                <button class="btn btn-primary" onclick="segmentImage()">üéØ Segment</button>
                <button class="btn btn-clear" onclick="clearPoints()">üóëÔ∏è Clear Points</button>
                <button class="btn btn-secondary" onclick="resetAll()">üîÑ Reset</button>
            </div>
        </div>
        
        <div class="status" id="status">
            <strong>Status:</strong> Ready to load models and process images
        </div>
        
        <div class="loading" id="loading">
            <div class="spinner"></div>
            <p>Processing on your phone's CPU...</p>
        </div>
        
        <div class="image-container" id="imageContainer" style="display: none;">
            <canvas id="canvas"></canvas>
            <div class="mask-overlay" id="maskOverlay"></div>
        </div>
        
        <div class="instructions">
            <h3>üìã How to Use:</h3>
            <ol>
                <li><strong>Upload an image</strong> or take a photo</li>
                <li><strong>Select point type</strong> (Positive/Negative)</li>
                <li><strong>Tap on objects</strong> you want to segment</li>
                <li><strong>Click "Segment"</strong> to process on your phone</li>
                <li><strong>Add more points</strong> to refine the segmentation</li>
            </ol>
        </div>
    </div>

    <script>
        class EnhancedMobileEdgeSAM {
            constructor() {
                this.encoderSession = null;
                this.decoderSession = null;
                this.imageData = null;
                this.points = [];
                this.labels = [];
                this.originalImage = null;
                this.canvas = null;
                this.ctx = null;
                this.isProcessing = false;
                this.imageFeatures = null; // Store image features like web demo
                
                this.initializeCanvas();
                this.loadModels();
            }
            
            async loadModels() {
                try {
                    this.updateStatus('Loading EdgeSAM models on your phone...');
                    
                    // Load ONNX models directly in browser
                    this.encoderSession = await ort.InferenceSession.create('./models/edge_sam_3x_encoder.onnx');
                    this.decoderSession = await ort.InferenceSession.create('./models/edge_sam_3x_decoder.onnx');
                    
                    this.updateStatus('‚úÖ Models loaded! Ready to process images on your phone');
                } catch (error) {
                    this.updateStatus('‚ùå Error loading models: ' + error.message);
                    console.error('Model loading error:', error);
                }
            }
            
            initializeCanvas() {
                this.canvas = document.getElementById('canvas');
                this.ctx = this.canvas.getContext('2d');
                
                // Add click listener for points
                this.canvas.addEventListener('click', (e) => {
                    if (this.isProcessing) return;
                    
                    const rect = this.canvas.getBoundingClientRect();
                    const x = e.clientX - rect.left;
                    const y = e.clientY - rect.top;
                    
                    this.addPoint(x, y);
                });
            }
            
            addPoint(x, y) {
                const pointType = document.querySelector('input[name="pointType"]:checked').value;
                const isPositive = pointType === 'positive';
                
                // Use the same coordinate system as the web demo
                // The web demo uses the display coordinates directly
                this.points.push([x, y]);
                this.labels.push(isPositive ? 1 : 0);
                
                // Visual feedback
                this.drawPoint(x, y, isPositive);
                
                console.log(`Added point: (${x}, ${y}) - ${isPositive ? 'positive' : 'negative'}`);
                this.updateStatus(`Added ${isPositive ? 'positive' : 'negative'} point. Total: ${this.points.length}`);
            }
            
            drawPoint(x, y, isPositive) {
                const point = document.createElement('div');
                point.className = `point ${isPositive ? 'positive' : 'negative'}`;
                point.style.left = x + 'px';
                point.style.top = y + 'px';
                document.getElementById('imageContainer').appendChild(point);
            }
            
            async segmentImage() {
                if (!this.encoderSession || !this.decoderSession) {
                    this.updateStatus('‚ùå Models not loaded yet');
                    return;
                }
                
                if (!this.imageData) {
                    this.updateStatus('‚ùå Please upload an image first');
                    return;
                }
                
                if (this.points.length === 0) {
                    this.updateStatus('‚ùå Please add some points first');
                    return;
                }
                
                this.isProcessing = true;
                this.showLoading(true);
                this.updateStatus('üîÑ Processing on your phone\'s CPU...');
                
                try {
                    // Use the same approach as the working web demo
                    // First get image features (like web demo's set_image)
                    const imageFeatures = await this.getImageFeatures();
                    
                    // Prepare point data exactly like web demo
                    const coord_np = new Float32Array(this.points.flat());
                    const label_np = new Float32Array(this.labels);
                    
                    console.log('Points being sent to model:', this.points);
                    console.log('Labels being sent to model:', this.labels);
                    
                    const pointCoordsTensor = new ort.Tensor('float32', coord_np, [1, this.points.length, 2]);
                    const pointLabelsTensor = new ort.Tensor('float32', label_np, [1, this.points.length]);
                    
                    // Run decoder with image features (like web demo)
                    const decoderResults = await this.decoderSession.run({
                        image_embeddings: imageFeatures,
                        point_coords: pointCoordsTensor,
                        point_labels: pointLabelsTensor
                    });
                    
                    // Process results like web demo
                    const masks = decoderResults.masks;
                    const scores = decoderResults.scores;
                    
                    console.log('Decoder results:', decoderResults);
                    console.log('Masks tensor:', {
                        dataType: masks.dataType,
                        dims: masks.dims,
                        dataLength: masks.data.length
                    });
                    console.log('Scores:', Array.from(scores.data));
                    
                    // Select best mask like web demo
                    const scoresArray = Array.from(scores.data);
                    const bestMaskIndex = scoresArray.indexOf(Math.max(...scoresArray));
                    
                    console.log('Best mask index:', bestMaskIndex);
                    
                    this.displayResults(masks, bestMaskIndex);
                    
                    this.updateStatus('‚úÖ Segmentation complete! Processed on your phone');
                    
                } catch (error) {
                    this.updateStatus('‚ùå Error during processing: ' + error.message);
                    console.error('Processing error:', error);
                } finally {
                    this.isProcessing = false;
                    this.showLoading(false);
                }
            }
            
            async getImageFeatures() {
                // This mimics the web demo's set_image functionality
                // We need to run the encoder to get image features
                const imageTensor = new ort.Tensor('float32', this.imageData, [1, 3, 1024, 1024]);
                
                const encoderResults = await this.encoderSession.run({
                    image: imageTensor
                });
                
                return encoderResults.image_embeddings;
            }
            
            displayResults(masks, bestMaskIndex) {
                console.log('Displaying results for masks:', masks);
                
                // Create mask overlay
                const maskOverlay = document.getElementById('maskOverlay');
                maskOverlay.innerHTML = '';
                
                // Convert masks to visual representation
                const maskData = this.processMasks(masks, bestMaskIndex);
                console.log('Processed mask data length:', maskData.length);
                console.log('Sample mask values:', maskData.slice(0, 10));
                
                const maskCanvas = document.createElement('canvas');
                maskCanvas.width = this.canvas.width;
                maskCanvas.height = this.canvas.height;
                const maskCtx = maskCanvas.getContext('2d');
                
                // Draw mask overlay using the same approach as web demo
                const imageData = maskCtx.createImageData(this.canvas.width, this.canvas.height);
                
                // Map canvas pixels to mask data
                for (let y = 0; y < this.canvas.height; y++) {
                    for (let x = 0; x < this.canvas.width; x++) {
                        // Map canvas coordinates to mask coordinates
                        const maskX = Math.floor((x / this.canvas.width) * 1024);
                        const maskY = Math.floor((y / this.canvas.height) * 1024);
                        
                        // Get mask value from the 1024x1024 mask
                        const maskIndex = maskY * 1024 + maskX;
                        
                        if (maskIndex < maskData.length && maskData[maskIndex] > 0.5) {
                            const pixelIndex = (y * this.canvas.width + x) * 4;
                            imageData.data[pixelIndex] = 30;      // R (like web demo)
                            imageData.data[pixelIndex + 1] = 144;  // G
                            imageData.data[pixelIndex + 2] = 255;  // B
                            imageData.data[pixelIndex + 3] = 153;  // A (0.6 opacity)
                        }
                    }
                }
                
                maskCtx.putImageData(imageData, 0, 0);
                maskOverlay.appendChild(maskCanvas);
                
                console.log('Mask overlay created and added to DOM');
            }
            
            processMasks(masks, bestMaskIndex) {
                console.log('Processing masks:', {
                    dims: masks.dims,
                    dataLength: masks.data.length,
                    bestMaskIndex: bestMaskIndex
                });
                
                // Convert ONNX tensor to usable format
                const maskArray = Array.from(masks.data);
                
                // Handle different tensor shapes
                if (masks.dims.length === 4) {
                    // Shape: [batch, channels, height, width] or [batch, height, width, channels]
                    const [batch, dim1, dim2, dim3] = masks.dims;
                    console.log('4D tensor shape:', masks.dims);
                    
                    // Take the best mask and flatten to 1024x1024
                    const flatMask = [];
                    const startIndex = bestMaskIndex * 1024 * 1024;
                    for (let i = 0; i < 1024 * 1024; i++) {
                        flatMask.push(maskArray[startIndex + i]);
                    }
                    return flatMask;
                } else if (masks.dims.length === 3) {
                    // Shape: [batch, height, width]
                    const [batch, height, width] = masks.dims;
                    console.log('3D tensor shape:', masks.dims);
                    
                    // Take the best mask and flatten to 1024x1024
                    const flatMask = [];
                    const startIndex = bestMaskIndex * 1024 * 1024;
                    for (let i = 0; i < 1024 * 1024; i++) {
                        flatMask.push(maskArray[startIndex + i]);
                    }
                    return flatMask;
                } else {
                    // Fallback: assume it's already flattened to 1024x1024
                    console.log('Using fallback processing - assuming 1024x1024');
                    return maskArray.slice(0, 1024 * 1024);
                }
            }
            
            async loadImage(file) {
                return new Promise((resolve, reject) => {
                    const reader = new FileReader();
                    reader.onload = (e) => {
                        const img = new Image();
                        img.onload = () => {
                            // Use the same image processing as web demo
                            const inputSize = 1024;
                            const w = img.width;
                            const h = img.height;
                            const scale = inputSize / Math.max(w, h);
                            const newW = Math.floor(w * scale);
                            const newH = Math.floor(h * scale);
                            
                            // Set canvas to the resized dimensions
                            this.canvas.width = newW;
                            this.canvas.height = newH;
                            
                            // Draw resized image
                            this.ctx.drawImage(img, 0, 0, newW, newH);
                            
                            console.log(`Image resized: ${w}x${h} -> ${newW}x${newH} (scale: ${scale})`);
                            
                            // Prepare image data for ONNX (same as web demo)
                            const imageData = this.prepareImageData(img);
                            
                            this.imageData = imageData;
                            this.originalImage = img;
                            
                            // Show image container
                            document.getElementById('imageContainer').style.display = 'block';
                            
                            resolve(imageData);
                        };
                        img.src = e.target.result;
                    };
                    reader.readAsDataURL(file);
                });
            }
            
            prepareImageData(img) {
                // Create a temporary canvas to process the image (same as web demo)
                const tempCanvas = document.createElement('canvas');
                tempCanvas.width = 1024;
                tempCanvas.height = 1024;
                const tempCtx = tempCanvas.getContext('2d');
                
                // Resize image to fit within 1024x1024 while maintaining aspect ratio
                const inputSize = 1024;
                const w = img.width;
                const h = img.height;
                const scale = inputSize / Math.max(w, h);
                const newW = Math.floor(w * scale);
                const newH = Math.floor(h * scale);
                
                // Center the image on 1024x1024 canvas
                const offsetX = (1024 - newW) / 2;
                const offsetY = (1024 - newH) / 2;
                
                // Draw resized image centered
                tempCtx.drawImage(img, offsetX, offsetY, newW, newH);
                
                // Get image data
                const imageData = tempCtx.getImageData(0, 0, 1024, 1024);
                const data = imageData.data;
                
                // Convert to Float32Array for ONNX (CHW format: Channel, Height, Width)
                const floatData = new Float32Array(3 * 1024 * 1024);
                
                // Normalize and rearrange data (CHW format for ONNX) - same as web demo
                for (let i = 0; i < 1024 * 1024; i++) {
                    // R channel
                    floatData[i] = (data[i * 4] - 123.675) / 58.395;
                    // G channel  
                    floatData[1024 * 1024 + i] = (data[i * 4 + 1] - 116.28) / 57.12;
                    // B channel
                    floatData[2 * 1024 * 1024 + i] = (data[i * 4 + 2] - 103.53) / 57.375;
                }
                
                console.log('Image data prepared:', {
                    length: floatData.length,
                    shape: [1, 3, 1024, 1024],
                    sample: Array.from(floatData.slice(0, 10))
                });
                
                return floatData;
            }
            
            clearPoints() {
                this.points = [];
                this.labels = [];
                
                // Remove visual points
                const points = document.querySelectorAll('.point');
                points.forEach(point => point.remove());
                
                this.updateStatus('Points cleared');
            }
            
            resetAll() {
                this.clearPoints();
                this.imageData = null;
                this.originalImage = null;
                this.imageFeatures = null;
                
                // Clear canvas
                this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);
                
                // Hide image container
                document.getElementById('imageContainer').style.display = 'none';
                
                // Clear mask overlay
                const maskOverlay = document.getElementById('maskOverlay');
                maskOverlay.innerHTML = '';
                
                this.updateStatus('Reset complete - ready for new image');
            }
            
            updateStatus(message) {
                document.getElementById('status').innerHTML = `<strong>Status:</strong> ${message}`;
            }
            
            showLoading(show) {
                document.getElementById('loading').style.display = show ? 'block' : 'none';
            }
        }
        
        // Initialize the application
        const app = new EnhancedMobileEdgeSAM();
        
        // File input handler
        document.getElementById('imageInput').addEventListener('change', async (e) => {
            const file = e.target.files[0];
            if (file) {
                try {
                    app.updateStatus('Loading image...');
                    await app.loadImage(file);
                    app.updateStatus('‚úÖ Image loaded! Click on objects to segment');
                } catch (error) {
                    app.updateStatus('‚ùå Error loading image: ' + error.message);
                    console.error('Image loading error:', error);
                }
            }
        });
        
        // Global functions for buttons
        function segmentImage() {
            app.segmentImage();
        }
        
        function clearPoints() {
            app.clearPoints();
        }
        
        function resetAll() {
            app.resetAll();
        }
    </script>
</body>
</html>
  